# custom_RAG-LLAMA_2
A custom RAG pipeline to answer questions from a textbook

In this project I have created a custom RAG pipeline from scratch using Langchain & HuggingFace Libraries and I have used <b>LLAMA_2-7b-chat-hf</b> as a foundational LLM model.
For vector store, I have used Chroma DB and HuggingFaceInstructEmbeddings as a text embedding model.
I have also implmented GUI using streamlit python framework for interacting with this custom RAG pipeline.
